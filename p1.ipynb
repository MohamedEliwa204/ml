{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-24T13:41:55.540952Z",
     "start_time": "2025-12-24T13:41:55.526889Z"
    }
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:41:55.653811Z",
     "start_time": "2025-12-24T13:41:55.594177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "df = pd.read_csv(\"California_Houses.csv\")\n",
    "\n",
    "df.info()"
   ],
   "id": "5a6ded34961b692d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Median_House_Value        20640 non-null  float64\n",
      " 1   Median_Income             20640 non-null  float64\n",
      " 2   Median_Age                20640 non-null  int64  \n",
      " 3   Tot_Rooms                 20640 non-null  int64  \n",
      " 4   Tot_Bedrooms              20640 non-null  int64  \n",
      " 5   Population                20640 non-null  int64  \n",
      " 6   Households                20640 non-null  int64  \n",
      " 7   Latitude                  20640 non-null  float64\n",
      " 8   Longitude                 20640 non-null  float64\n",
      " 9   Distance_to_coast         20640 non-null  float64\n",
      " 10  Distance_to_LA            20640 non-null  float64\n",
      " 11  Distance_to_SanDiego      20640 non-null  float64\n",
      " 12  Distance_to_SanJose       20640 non-null  float64\n",
      " 13  Distance_to_SanFrancisco  20640 non-null  float64\n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:41:55.689114Z",
     "start_time": "2025-12-24T13:41:55.683569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X = df.drop(\"Median_House_Value\", axis=1)\n",
    "y = df[\"Median_House_Value\"]\n",
    "\n"
   ],
   "id": "6ce6af64d21b0889",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:41:55.739892Z",
     "start_time": "2025-12-24T13:41:55.728074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val,y_test = train_test_split(\n",
    "     X_temp, y_temp, test_size=0.50, random_state=42\n",
    ")\n",
    "\n",
    "total_rows = len(df)\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Training set:   {len(X_train)} rows ({len(X_train)/total_rows:.2%})\")\n",
    "print(f\"Validation set: {len(X_val)} rows ({len(X_val)/total_rows:.2%})\")\n",
    "print(f\"Testing set:    {len(X_test)} rows ({len(X_test)/total_rows:.2%})\")"
   ],
   "id": "25c68a8fc28d430c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 20640\n",
      "Training set:   14448 rows (70.00%)\n",
      "Validation set: 3096 rows (15.00%)\n",
      "Testing set:    3096 rows (15.00%)\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:41:55.809934Z",
     "start_time": "2025-12-24T13:41:55.793041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# scaling the data first so could apply regularization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train = y_train / 100000\n",
    "y_val = y_val / 100000\n",
    "y_test = y_test / 100000\n"
   ],
   "id": "1fef99123379a0da",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:41:55.830969Z",
     "start_time": "2025-12-24T13:41:55.822139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomRegressor:\n",
    "    def __init__(self, X, y, epochs=100, penalty=None,  gradient_method=\"batch\"):\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.penalty=penalty\n",
    "\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.gradient_method = gradient_method\n",
    "    def fit(self,learning_rate=0.01, lambd=0):\n",
    "\n",
    "        self.lambd=lambd\n",
    "        self.learning_rate=learning_rate\n",
    "        n_samples, n_features = self.X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        for i in range(self.epochs):\n",
    "            if self.gradient_method == \"batch\":\n",
    "                y_predicted = np.dot(self.X, self.weights) + self.bias\n",
    "                dw = (1/n_samples) * np.dot(self.X.T, (y_predicted - self.y)) # X.T is the xj in the gradient descent(row reppresent feature and coluumn represent sample) as now each row in X.T represent feature, and as they are vectors the loop is implicity inside them\n",
    "                db = (1/n_samples) * np.sum(y_predicted - self.y)\n",
    "\n",
    "                if self.penalty == \"l2\":\n",
    "                    dw += 2 * self.lambd * (self.weights)\n",
    "                elif self.penalty == \"l1\":\n",
    "                    dw += (self.lambd) * np.sign(self.weights) # diffrentiate the w multiplied with constant so remain the constant with the sign of w\n",
    "\n",
    "                self.weights -= self.learning_rate * dw\n",
    "                self.bias  -= self.learning_rate * db\n",
    "            elif self.gradient_method == \"sgd\":\n",
    "\n",
    "                indices = np.random.permutation(n_samples)\n",
    "                for idx in indices:\n",
    "                    xi = self.X[idx:idx+1]\n",
    "                    yi = self.y.iloc[idx]\n",
    "                    y_pred = np.dot(xi, self.weights) + self.bias\n",
    "                    dw = np.dot(xi.T, (y_pred - yi)).flatten()\n",
    "                    db = (y_pred - yi).item()\n",
    "\n",
    "                    if self.penalty == \"l2\":\n",
    "                        dw += 2 * self.lambd * (self.weights)\n",
    "                    elif self.penalty == \"l1\":\n",
    "                        dw += self.lambd * np.sign(self.weights)\n",
    "\n",
    "                    self.weights -= self.learning_rate * dw\n",
    "                    self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ],
   "id": "26144d4b7ac582a5",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:41:55.847194Z",
     "start_time": "2025-12-24T13:41:55.840880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def grid_search(X_train, y_train, X_val, y_val, penalty_type, optimizer_type):\n",
    "    print(f\"--- Tuning {penalty_type} ({optimizer_type}) ---\")\n",
    "\n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    if optimizer_type == \"batch\":\n",
    "        learning_rates = [0.1, 0.01, 0.001]\n",
    "    else:\n",
    "        learning_rates = [0.001, 0.0001, 0.00001]\n",
    "\n",
    "    if penalty_type is None:\n",
    "        lambdas=[0]\n",
    "    else:\n",
    "        lambdas = [0, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "    epochs = 100 if optimizer_type == \"batch\" else 20\n",
    "\n",
    "    for lr, l in itertools.product(learning_rates, lambdas):\n",
    "        model = CustomRegressor(X_train, y_train, epochs, penalty_type, optimizer_type)\n",
    "        model.fit(lr, l)\n",
    "        preds = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = {'learning_rate': lr, 'lambd': l}\n",
    "\n",
    "\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "    print(f\"Best Validation MSE: {best_mse:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "    return best_params\n"
   ],
   "id": "7808530ebedd9e94",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:45:53.874352Z",
     "start_time": "2025-12-24T13:41:55.858977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_ridge_batch = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l2\", \"batch\")\n",
    "best_lasso_batch = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l1\", \"batch\")\n",
    "\n",
    "best_ridge_sgd = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l2\", \"sgd\")\n",
    "\n",
    "best_linear_batch = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, None, \"batch\")\n",
    "\n",
    "best_linear_sgd = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, None, \"sgd\")\n",
    "\n",
    "\n",
    "\n",
    "best_lasso_sgd = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l1\", \"sgd\")\n",
    "\n"
   ],
   "id": "69df8a26ec071dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning l2 (batch) ---\n",
      "Best Params: {'learning_rate': 0.1, 'lambd': 0}\n",
      "Best Validation MSE: 0.51\n",
      "------------------------------\n",
      "--- Tuning l1 (batch) ---\n",
      "Best Params: {'learning_rate': 0.1, 'lambd': 0}\n",
      "Best Validation MSE: 0.51\n",
      "------------------------------\n",
      "--- Tuning l2 (sgd) ---\n",
      "Best Params: {'learning_rate': 0.001, 'lambd': 0}\n",
      "Best Validation MSE: 0.49\n",
      "------------------------------\n",
      "--- Tuning None (batch) ---\n",
      "Best Params: {'learning_rate': 0.1, 'lambd': 0}\n",
      "Best Validation MSE: 0.51\n",
      "------------------------------\n",
      "--- Tuning None (sgd) ---\n",
      "Best Params: {'learning_rate': 0.0001, 'lambd': 0}\n",
      "Best Validation MSE: 0.50\n",
      "------------------------------\n",
      "--- Tuning l1 (sgd) ---\n",
      "Best Params: {'learning_rate': 0.001, 'lambd': 0.001}\n",
      "Best Validation MSE: 0.49\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:46:09.445374Z",
     "start_time": "2025-12-24T13:45:54.032092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_configs = [\n",
    "    (\"Linear Regression (Batch)\", best_linear_batch, None, \"batch\"),\n",
    "    (\"Linear Regression (SGD)\",   best_linear_sgd,   None, \"sgd\"),\n",
    "    (\"Ridge Regression (Batch)\",  best_ridge_batch,  \"l2\", \"batch\"),\n",
    "    (\"Ridge Regression (SGD)\",    best_ridge_sgd,    \"l2\", \"sgd\"),\n",
    "    (\"Lasso Regression (Batch)\",  best_lasso_batch,  \"l1\", \"batch\"),\n",
    "    (\"Lasso Regression (SGD)\",    best_lasso_sgd,    \"l1\", \"sgd\"),\n",
    "]\n",
    "\n",
    "results_data = []\n",
    "feature_names = X_train.columns\n",
    "\n",
    "weights_report = []\n",
    "print(\"--- FINAL TESTING RESULTS ---\\n\")\n",
    "\n",
    "# 2. Loop through each configuration\n",
    "for name, params, penalty, optimizer in final_configs:\n",
    "\n",
    "\n",
    "    model = CustomRegressor(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        epochs=100 if optimizer == \"batch\" else 20,\n",
    "        penalty=penalty,\n",
    "        gradient_method=optimizer\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(params['learning_rate'],params['lambd'])\n",
    "\n",
    "\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    results_data.append({\n",
    "        \"Model\": name,\n",
    "        \"Optimizer\": optimizer.upper(),\n",
    "        \"Best Lambda\": params['lambd'],\n",
    "        \"Best LR\": params['learning_rate'],\n",
    "        \"Test MSE\": mse,\n",
    "        \"Test R2\": r2\n",
    "    })\n",
    "    for feature, weight in zip(feature_names, model.weights):\n",
    "        weights_report.append({\n",
    "            \"Model\": name,\n",
    "            \"Feature\": feature,\n",
    "            \"Weight\": weight,\n",
    "            \"Penalty\": penalty if penalty else \"None\",\n",
    "            \"Optimizer\": optimizer.upper(),\n",
    "            \"Lambda\": params['lambd']\n",
    "        })\n",
    "\n",
    "    print(f\"{name}: MSE={mse:.2f}, R2={r2:.4f}\")\n",
    "\n",
    "\n",
    "weights_df = pd.DataFrame(weights_report)\n",
    "results_df = pd.DataFrame(results_data)\n",
    "weights_pivot = weights_df.pivot_table(index=\"Model\", columns=\"Feature\", values=\"Weight\")\n",
    "print(\"\\n--- LEADERBOARD ---\")\n",
    "display(results_df.sort_values(by=\"Test MSE\", ascending=True))\n",
    "display(weights_pivot)"
   ],
   "id": "fa52f994d611260a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL TESTING RESULTS ---\n",
      "\n",
      "Linear Regression (Batch): MSE=0.46, R2=0.6533\n",
      "Linear Regression (SGD): MSE=0.45, R2=0.6622\n",
      "Ridge Regression (Batch): MSE=0.46, R2=0.6533\n",
      "Ridge Regression (SGD): MSE=0.46, R2=0.6488\n",
      "Lasso Regression (Batch): MSE=0.46, R2=0.6533\n",
      "Lasso Regression (SGD): MSE=0.44, R2=0.6652\n",
      "\n",
      "--- LEADERBOARD ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                       Model Optimizer  Best Lambda  Best LR  Test MSE  \\\n",
       "5     Lasso Regression (SGD)       SGD        0.001   0.0010  0.442763   \n",
       "1    Linear Regression (SGD)       SGD        0.000   0.0001  0.446701   \n",
       "2   Ridge Regression (Batch)     BATCH        0.000   0.1000  0.458448   \n",
       "0  Linear Regression (Batch)     BATCH        0.000   0.1000  0.458448   \n",
       "4   Lasso Regression (Batch)     BATCH        0.000   0.1000  0.458448   \n",
       "3     Ridge Regression (SGD)       SGD        0.000   0.0010  0.464440   \n",
       "\n",
       "    Test R2  \n",
       "5  0.665160  \n",
       "1  0.662181  \n",
       "2  0.653297  \n",
       "0  0.653297  \n",
       "4  0.653297  \n",
       "3  0.648767  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Best Lambda</th>\n",
       "      <th>Best LR</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso Regression (SGD)</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.442763</td>\n",
       "      <td>0.665160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression (SGD)</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.446701</td>\n",
       "      <td>0.662181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression (Batch)</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.458448</td>\n",
       "      <td>0.653297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression (Batch)</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.458448</td>\n",
       "      <td>0.653297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso Regression (Batch)</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.458448</td>\n",
       "      <td>0.653297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge Regression (SGD)</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.464440</td>\n",
       "      <td>0.648767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Feature                    Distance_to_LA  Distance_to_SanDiego  \\\n",
       "Model                                                             \n",
       "Lasso Regression (Batch)        -0.201762             -0.020848   \n",
       "Lasso Regression (SGD)          -0.290214              0.091431   \n",
       "Linear Regression (Batch)       -0.201762             -0.020848   \n",
       "Linear Regression (SGD)         -0.282153              0.015585   \n",
       "Ridge Regression (Batch)        -0.201762             -0.020848   \n",
       "Ridge Regression (SGD)          -0.312986              0.292653   \n",
       "\n",
       "Feature                    Distance_to_SanFrancisco  Distance_to_SanJose  \\\n",
       "Model                                                                      \n",
       "Lasso Regression (Batch)                  -0.068252            -0.064922   \n",
       "Lasso Regression (SGD)                    -0.031261             0.074561   \n",
       "Linear Regression (Batch)                 -0.068252            -0.064922   \n",
       "Linear Regression (SGD)                   -0.053449            -0.010900   \n",
       "Ridge Regression (Batch)                  -0.068252            -0.064922   \n",
       "Ridge Regression (SGD)                    -0.209898             0.231115   \n",
       "\n",
       "Feature                    Distance_to_coast  Households  Latitude  Longitude  \\\n",
       "Model                                                                           \n",
       "Lasso Regression (Batch)           -0.276845    0.146292 -0.108615  -0.180531   \n",
       "Lasso Regression (SGD)             -0.140409    0.114936 -0.443435  -0.593839   \n",
       "Linear Regression (Batch)          -0.276845    0.146292 -0.108615  -0.180531   \n",
       "Linear Regression (SGD)            -0.233300    0.214387 -0.167912  -0.339986   \n",
       "Ridge Regression (Batch)           -0.276845    0.146292 -0.108615  -0.180531   \n",
       "Ridge Regression (SGD)             -0.136551    0.147930 -0.614212  -0.606817   \n",
       "\n",
       "Feature                    Median_Age  Median_Income  Population  \\\n",
       "Model                                                              \n",
       "Lasso Regression (Batch)     0.133482       0.706024   -0.353065   \n",
       "Lasso Regression (SGD)       0.112645       0.770201   -0.463522   \n",
       "Linear Regression (Batch)    0.133482       0.706024   -0.353065   \n",
       "Linear Regression (SGD)      0.121083       0.723334   -0.442245   \n",
       "Ridge Regression (Batch)     0.133482       0.706024   -0.353065   \n",
       "Ridge Regression (SGD)       0.130633       0.744273   -0.331888   \n",
       "\n",
       "Feature                    Tot_Bedrooms  Tot_Rooms  \n",
       "Model                                               \n",
       "Lasso Regression (Batch)       0.209738   0.048588  \n",
       "Lasso Regression (SGD)         0.483197  -0.090085  \n",
       "Linear Regression (Batch)      0.209738   0.048588  \n",
       "Linear Regression (SGD)        0.341311  -0.049250  \n",
       "Ridge Regression (Batch)       0.209738   0.048588  \n",
       "Ridge Regression (SGD)         0.487985  -0.104218  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Distance_to_LA</th>\n",
       "      <th>Distance_to_SanDiego</th>\n",
       "      <th>Distance_to_SanFrancisco</th>\n",
       "      <th>Distance_to_SanJose</th>\n",
       "      <th>Distance_to_coast</th>\n",
       "      <th>Households</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Median_Income</th>\n",
       "      <th>Population</th>\n",
       "      <th>Tot_Bedrooms</th>\n",
       "      <th>Tot_Rooms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso Regression (Batch)</th>\n",
       "      <td>-0.201762</td>\n",
       "      <td>-0.020848</td>\n",
       "      <td>-0.068252</td>\n",
       "      <td>-0.064922</td>\n",
       "      <td>-0.276845</td>\n",
       "      <td>0.146292</td>\n",
       "      <td>-0.108615</td>\n",
       "      <td>-0.180531</td>\n",
       "      <td>0.133482</td>\n",
       "      <td>0.706024</td>\n",
       "      <td>-0.353065</td>\n",
       "      <td>0.209738</td>\n",
       "      <td>0.048588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression (SGD)</th>\n",
       "      <td>-0.290214</td>\n",
       "      <td>0.091431</td>\n",
       "      <td>-0.031261</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>-0.140409</td>\n",
       "      <td>0.114936</td>\n",
       "      <td>-0.443435</td>\n",
       "      <td>-0.593839</td>\n",
       "      <td>0.112645</td>\n",
       "      <td>0.770201</td>\n",
       "      <td>-0.463522</td>\n",
       "      <td>0.483197</td>\n",
       "      <td>-0.090085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression (Batch)</th>\n",
       "      <td>-0.201762</td>\n",
       "      <td>-0.020848</td>\n",
       "      <td>-0.068252</td>\n",
       "      <td>-0.064922</td>\n",
       "      <td>-0.276845</td>\n",
       "      <td>0.146292</td>\n",
       "      <td>-0.108615</td>\n",
       "      <td>-0.180531</td>\n",
       "      <td>0.133482</td>\n",
       "      <td>0.706024</td>\n",
       "      <td>-0.353065</td>\n",
       "      <td>0.209738</td>\n",
       "      <td>0.048588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression (SGD)</th>\n",
       "      <td>-0.282153</td>\n",
       "      <td>0.015585</td>\n",
       "      <td>-0.053449</td>\n",
       "      <td>-0.010900</td>\n",
       "      <td>-0.233300</td>\n",
       "      <td>0.214387</td>\n",
       "      <td>-0.167912</td>\n",
       "      <td>-0.339986</td>\n",
       "      <td>0.121083</td>\n",
       "      <td>0.723334</td>\n",
       "      <td>-0.442245</td>\n",
       "      <td>0.341311</td>\n",
       "      <td>-0.049250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression (Batch)</th>\n",
       "      <td>-0.201762</td>\n",
       "      <td>-0.020848</td>\n",
       "      <td>-0.068252</td>\n",
       "      <td>-0.064922</td>\n",
       "      <td>-0.276845</td>\n",
       "      <td>0.146292</td>\n",
       "      <td>-0.108615</td>\n",
       "      <td>-0.180531</td>\n",
       "      <td>0.133482</td>\n",
       "      <td>0.706024</td>\n",
       "      <td>-0.353065</td>\n",
       "      <td>0.209738</td>\n",
       "      <td>0.048588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression (SGD)</th>\n",
       "      <td>-0.312986</td>\n",
       "      <td>0.292653</td>\n",
       "      <td>-0.209898</td>\n",
       "      <td>0.231115</td>\n",
       "      <td>-0.136551</td>\n",
       "      <td>0.147930</td>\n",
       "      <td>-0.614212</td>\n",
       "      <td>-0.606817</td>\n",
       "      <td>0.130633</td>\n",
       "      <td>0.744273</td>\n",
       "      <td>-0.331888</td>\n",
       "      <td>0.487985</td>\n",
       "      <td>-0.104218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:46:10.059744Z",
     "start_time": "2025-12-24T13:46:10.055523Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3d063fff8a757bc1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
