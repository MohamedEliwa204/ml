{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-24T18:13:27.762130Z",
     "start_time": "2025-12-24T18:13:18.534363Z"
    }
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:13:28.447424Z",
     "start_time": "2025-12-24T18:13:27.807412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(42)\n",
    "df = pd.read_csv(\"California_Houses.csv\")\n",
    "\n",
    "df.info()"
   ],
   "id": "5a6ded34961b692d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Median_House_Value        20640 non-null  float64\n",
      " 1   Median_Income             20640 non-null  float64\n",
      " 2   Median_Age                20640 non-null  int64  \n",
      " 3   Tot_Rooms                 20640 non-null  int64  \n",
      " 4   Tot_Bedrooms              20640 non-null  int64  \n",
      " 5   Population                20640 non-null  int64  \n",
      " 6   Households                20640 non-null  int64  \n",
      " 7   Latitude                  20640 non-null  float64\n",
      " 8   Longitude                 20640 non-null  float64\n",
      " 9   Distance_to_coast         20640 non-null  float64\n",
      " 10  Distance_to_LA            20640 non-null  float64\n",
      " 11  Distance_to_SanDiego      20640 non-null  float64\n",
      " 12  Distance_to_SanJose       20640 non-null  float64\n",
      " 13  Distance_to_SanFrancisco  20640 non-null  float64\n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:13:28.483243Z",
     "start_time": "2025-12-24T18:13:28.473942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X = df.drop(\"Median_House_Value\", axis=1)\n",
    "y = df[\"Median_House_Value\"]\n",
    "\n"
   ],
   "id": "6ce6af64d21b0889",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:13:28.611206Z",
     "start_time": "2025-12-24T18:13:28.565552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val,y_test = train_test_split(\n",
    "     X_temp, y_temp, test_size=0.50, random_state=42\n",
    ")\n",
    "\n",
    "total_rows = len(df)\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Training set:   {len(X_train)} rows ({len(X_train)/total_rows:.2%})\")\n",
    "print(f\"Validation set: {len(X_val)} rows ({len(X_val)/total_rows:.2%})\")\n",
    "print(f\"Testing set:    {len(X_test)} rows ({len(X_test)/total_rows:.2%})\")"
   ],
   "id": "25c68a8fc28d430c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 20640\n",
      "Training set:   14448 rows (70.00%)\n",
      "Validation set: 3096 rows (15.00%)\n",
      "Testing set:    3096 rows (15.00%)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:13:28.686773Z",
     "start_time": "2025-12-24T18:13:28.668614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# scaling the data first so could apply regularization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# y_train = y_train / 100000\n",
    "# y_val = y_val / 100000\n",
    "# y_test = y_test / 100000\n"
   ],
   "id": "1fef99123379a0da",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:13:28.718009Z",
     "start_time": "2025-12-24T18:13:28.707530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomRegressor:\n",
    "    def __init__(self, X, y, epochs=100, penalty=None,  gradient_method=\"batch\"):\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.penalty=penalty\n",
    "\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.gradient_method = gradient_method\n",
    "    def fit(self,learning_rate=0.01, lambd=0):\n",
    "\n",
    "        self.lambd=lambd\n",
    "        self.learning_rate=learning_rate\n",
    "        n_samples, n_features = self.X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        for i in range(self.epochs):\n",
    "            if self.gradient_method == \"batch\":\n",
    "                y_predicted = np.dot(self.X, self.weights) + self.bias\n",
    "                dw = (1/n_samples) * np.dot(self.X.T, (y_predicted - self.y)) # X.T is the xj in the gradient descent(row reppresent feature and coluumn represent sample) as now each row in X.T represent feature, and as they are vectors the loop is implicity inside them\n",
    "                db = (1/n_samples) * np.sum(y_predicted - self.y)\n",
    "\n",
    "                if self.penalty == \"l2\":\n",
    "                    dw +=  (self.lambd/n_samples) * (self.weights)\n",
    "                elif self.penalty == \"l1\":\n",
    "                    dw += 0.5 * (self.lambd/n_samples) * np.sign(self.weights) # diffrentiate the w multiplied with constant so remain the constant with the sign of w\n",
    "\n",
    "                self.weights -= self.learning_rate * dw\n",
    "                self.bias  -= self.learning_rate * db\n",
    "            elif self.gradient_method == \"sgd\":\n",
    "\n",
    "                indices = np.random.permutation(n_samples)\n",
    "                for idx in indices:\n",
    "                    xi = self.X[idx:idx+1]\n",
    "                    yi = self.y.iloc[idx]\n",
    "                    y_pred = np.dot(xi, self.weights) + self.bias\n",
    "                    dw = np.dot(xi.T, (y_pred - yi)).flatten()\n",
    "                    db = (y_pred - yi).item()\n",
    "\n",
    "                    if self.penalty == \"l2\":\n",
    "                        dw += self.lambd * (self.weights) # not divide on n_samples as 1 sample\n",
    "                    elif self.penalty == \"l1\":\n",
    "                        dw += 0.5 * self.lambd * np.sign(self.weights)\n",
    "\n",
    "                    self.weights -= self.learning_rate * dw\n",
    "                    self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ],
   "id": "26144d4b7ac582a5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:13:28.734494Z",
     "start_time": "2025-12-24T18:13:28.728464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def grid_search(X_train, y_train, X_val, y_val, penalty_type, optimizer_type):\n",
    "    print(f\"--- Tuning {penalty_type} ({optimizer_type}) ---\")\n",
    "\n",
    "    best_mse = float('inf')\n",
    "    best_params = {}\n",
    "    if optimizer_type == \"batch\":\n",
    "        learning_rates = [0.1, 0.01, 0.001]\n",
    "    else:\n",
    "        learning_rates = [0.001, 0.0001, 0.00001]\n",
    "\n",
    "    if penalty_type is None:\n",
    "        lambdas=[0]\n",
    "    else:\n",
    "        lambdas = [ 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "    epochs = 100 if optimizer_type == \"batch\" else 20\n",
    "\n",
    "    for lr, l in itertools.product(learning_rates, lambdas):\n",
    "        model = CustomRegressor(X_train, y_train, epochs, penalty_type, optimizer_type)\n",
    "        model.fit(lr, l)\n",
    "        preds = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_params = {'learning_rate': lr, 'lambd': l}\n",
    "\n",
    "\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "    print(f\"Best Validation MSE: {best_mse:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "    return best_params\n"
   ],
   "id": "7808530ebedd9e94",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:16:59.703529Z",
     "start_time": "2025-12-24T18:13:28.744463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_ridge_batch = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l2\", \"batch\")\n",
    "best_lasso_batch = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l1\", \"batch\")\n",
    "\n",
    "best_ridge_sgd = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l2\", \"sgd\")\n",
    "\n",
    "best_linear_batch = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, None, \"batch\")\n",
    "\n",
    "best_linear_sgd = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, None, \"sgd\")\n",
    "\n",
    "\n",
    "\n",
    "best_lasso_sgd = grid_search(X_train_scaled, y_train, X_val_scaled, y_val, \"l1\", \"sgd\")\n",
    "\n"
   ],
   "id": "69df8a26ec071dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning l2 (batch) ---\n",
      "Best Params: {'learning_rate': 0.1, 'lambd': 0.001}\n",
      "Best Validation MSE: 5098959077.22\n",
      "------------------------------\n",
      "--- Tuning l1 (batch) ---\n",
      "Best Params: {'learning_rate': 0.1, 'lambd': 0.001}\n",
      "Best Validation MSE: 5098959018.49\n",
      "------------------------------\n",
      "--- Tuning l2 (sgd) ---\n",
      "Best Params: {'learning_rate': 0.001, 'lambd': 0.001}\n",
      "Best Validation MSE: 4936260270.54\n",
      "------------------------------\n",
      "--- Tuning None (batch) ---\n",
      "Best Params: {'learning_rate': 0.1, 'lambd': 0}\n",
      "Best Validation MSE: 5098959018.48\n",
      "------------------------------\n",
      "--- Tuning None (sgd) ---\n",
      "Best Params: {'learning_rate': 0.0001, 'lambd': 0}\n",
      "Best Validation MSE: 4988695516.46\n",
      "------------------------------\n",
      "--- Tuning l1 (sgd) ---\n",
      "Best Params: {'learning_rate': 0.001, 'lambd': 10}\n",
      "Best Validation MSE: 4934867459.31\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:17:15.319447Z",
     "start_time": "2025-12-24T18:17:00.273786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_configs = [\n",
    "    (\"Linear Regression (Batch)\", best_linear_batch, None, \"batch\"),\n",
    "    (\"Linear Regression (SGD)\",   best_linear_sgd,   None, \"sgd\"),\n",
    "    (\"Ridge Regression (Batch)\",  best_ridge_batch,  \"l2\", \"batch\"),\n",
    "    (\"Ridge Regression (SGD)\",    best_ridge_sgd,    \"l2\", \"sgd\"),\n",
    "    (\"Lasso Regression (Batch)\",  best_lasso_batch,  \"l1\", \"batch\"),\n",
    "    (\"Lasso Regression (SGD)\",    best_lasso_sgd,    \"l1\", \"sgd\"),\n",
    "]\n",
    "\n",
    "results_data = []\n",
    "feature_names = X_train.columns\n",
    "\n",
    "weights_report = []\n",
    "print(\"--- FINAL TESTING RESULTS ---\\n\")\n",
    "\n",
    "# 2. Loop through each configuration\n",
    "for name, params, penalty, optimizer in final_configs:\n",
    "\n",
    "\n",
    "    model = CustomRegressor(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        epochs=100 if optimizer == \"batch\" else 20,\n",
    "        penalty=penalty,\n",
    "        gradient_method=optimizer\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(params['learning_rate'],params['lambd'])\n",
    "\n",
    "\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    results_data.append({\n",
    "        \"Model\": name,\n",
    "        \"Optimizer\": optimizer.upper(),\n",
    "        \"Best Lambda\": params['lambd'],\n",
    "        \"Best LR\": params['learning_rate'],\n",
    "        \"Test MSE\": mse,\n",
    "        \"Test R2\": r2,\n",
    "        \"Train MSE\":mse_train,\n",
    "        \"Train R2\": r2_train\n",
    "    })\n",
    "    for feature, weight in zip(feature_names, model.weights):\n",
    "        weights_report.append({\n",
    "            \"Model\": name,\n",
    "            \"Feature\": feature,\n",
    "            \"Weight\": weight,\n",
    "            \"Penalty\": penalty if penalty else \"None\",\n",
    "            \"Optimizer\": optimizer.upper(),\n",
    "            \"Lambda\": params['lambd']\n",
    "        })\n",
    "\n",
    "    print(f\"{name}: MSE={mse:.2f}, R2={r2:.4f}\")\n",
    "\n",
    "\n",
    "weights_df = pd.DataFrame(weights_report)\n",
    "results_df = pd.DataFrame(results_data)\n",
    "weights_pivot = weights_df.pivot_table(index=\"Model\", columns=\"Feature\", values=\"Weight\")\n",
    "print(\"\\n--- LEADERBOARD ---\")\n",
    "display(results_df.sort_values(by=\"Test MSE\", ascending=True))\n",
    "display(weights_pivot)"
   ],
   "id": "fa52f994d611260a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL TESTING RESULTS ---\n",
      "\n",
      "Linear Regression (Batch): MSE=4584484438.66, R2=0.6533\n",
      "Linear Regression (SGD): MSE=4461840676.87, R2=0.6626\n",
      "Ridge Regression (Batch): MSE=4584484539.75, R2=0.6533\n",
      "Ridge Regression (SGD): MSE=4397593453.86, R2=0.6674\n",
      "Lasso Regression (Batch): MSE=4584484438.66, R2=0.6533\n",
      "Lasso Regression (SGD): MSE=4442690785.90, R2=0.6640\n",
      "\n",
      "--- LEADERBOARD ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                       Model Optimizer  Best Lambda  Best LR      Test MSE  \\\n",
       "3     Ridge Regression (SGD)       SGD        0.001   0.0010  4.397593e+09   \n",
       "5     Lasso Regression (SGD)       SGD       10.000   0.0010  4.442691e+09   \n",
       "1    Linear Regression (SGD)       SGD        0.000   0.0001  4.461841e+09   \n",
       "0  Linear Regression (Batch)     BATCH        0.000   0.1000  4.584484e+09   \n",
       "4   Lasso Regression (Batch)     BATCH        0.001   0.1000  4.584484e+09   \n",
       "2   Ridge Regression (Batch)     BATCH        0.001   0.1000  4.584485e+09   \n",
       "\n",
       "    Test R2     Train MSE  Train R2  \n",
       "3  0.667431  4.751943e+09  0.645297  \n",
       "5  0.664021  4.774016e+09  0.643649  \n",
       "1  0.662572  4.799546e+09  0.641744  \n",
       "0  0.653297  4.896828e+09  0.634482  \n",
       "4  0.653297  4.896828e+09  0.634482  \n",
       "2  0.653297  4.896828e+09  0.634482  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Best Lambda</th>\n",
       "      <th>Best LR</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Train R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge Regression (SGD)</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4.397593e+09</td>\n",
       "      <td>0.667431</td>\n",
       "      <td>4.751943e+09</td>\n",
       "      <td>0.645297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso Regression (SGD)</td>\n",
       "      <td>SGD</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4.442691e+09</td>\n",
       "      <td>0.664021</td>\n",
       "      <td>4.774016e+09</td>\n",
       "      <td>0.643649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression (SGD)</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4.461841e+09</td>\n",
       "      <td>0.662572</td>\n",
       "      <td>4.799546e+09</td>\n",
       "      <td>0.641744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression (Batch)</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4.584484e+09</td>\n",
       "      <td>0.653297</td>\n",
       "      <td>4.896828e+09</td>\n",
       "      <td>0.634482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso Regression (Batch)</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4.584484e+09</td>\n",
       "      <td>0.653297</td>\n",
       "      <td>4.896828e+09</td>\n",
       "      <td>0.634482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression (Batch)</td>\n",
       "      <td>BATCH</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>4.584485e+09</td>\n",
       "      <td>0.653297</td>\n",
       "      <td>4.896828e+09</td>\n",
       "      <td>0.634482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Feature                    Distance_to_LA  Distance_to_SanDiego  \\\n",
       "Model                                                             \n",
       "Lasso Regression (Batch)    -20176.185162          -2084.835722   \n",
       "Lasso Regression (SGD)      -32034.923775          27689.312301   \n",
       "Linear Regression (Batch)   -20176.185162          -2084.835722   \n",
       "Linear Regression (SGD)     -28008.391224           1816.559226   \n",
       "Ridge Regression (Batch)    -20176.180846          -2084.836299   \n",
       "Ridge Regression (SGD)      -30729.532934          24890.138073   \n",
       "\n",
       "Feature                    Distance_to_SanFrancisco  Distance_to_SanJose  \\\n",
       "Model                                                                      \n",
       "Lasso Regression (Batch)               -6825.152954         -6492.168786   \n",
       "Lasso Regression (SGD)                -20856.307251         21540.429826   \n",
       "Linear Regression (Batch)              -6825.152954         -6492.168786   \n",
       "Linear Regression (SGD)                -5671.379385         -1293.516133   \n",
       "Ridge Regression (Batch)               -6825.152615         -6492.168945   \n",
       "Ridge Regression (SGD)                -18295.015591         20815.974634   \n",
       "\n",
       "Feature                    Distance_to_coast    Households      Latitude  \\\n",
       "Model                                                                      \n",
       "Lasso Regression (Batch)       -27684.457405  14629.191393 -10861.516412   \n",
       "Lasso Regression (SGD)         -15324.856167  12800.377819 -61241.041903   \n",
       "Linear Regression (Batch)      -27684.457405  14629.191393 -10861.516412   \n",
       "Linear Regression (SGD)        -23470.632090  20885.065028 -16572.175371   \n",
       "Ridge Regression (Batch)       -27684.457945  14629.187268 -10861.515065   \n",
       "Ridge Regression (SGD)         -13401.047652  13899.321323 -56603.380009   \n",
       "\n",
       "Feature                       Longitude    Median_Age  Median_Income  \\\n",
       "Model                                                                  \n",
       "Lasso Regression (Batch)  -18053.058686  13348.160105   70602.433193   \n",
       "Lasso Regression (SGD)    -60343.644862  11063.575181   75246.628090   \n",
       "Linear Regression (Batch) -18053.058687  13348.160105   70602.433193   \n",
       "Linear Regression (SGD)   -34247.249948  12961.537953   72603.361972   \n",
       "Ridge Regression (Batch)  -18053.054345  13348.159007   70602.428214   \n",
       "Ridge Regression (SGD)    -57823.532751  11002.184735   75063.448330   \n",
       "\n",
       "Feature                      Population  Tot_Bedrooms     Tot_Rooms  \n",
       "Model                                                                \n",
       "Lasso Regression (Batch)  -35306.545245  20973.774202   4858.812241  \n",
       "Lasso Regression (SGD)    -40719.297069  47442.497916 -12068.668878  \n",
       "Linear Regression (Batch) -35306.545246  20973.774202   4858.812241  \n",
       "Linear Regression (SGD)   -45007.535020  33638.233951  -5338.291288  \n",
       "Ridge Regression (Batch)  -35306.536058  20973.767744   4858.813852  \n",
       "Ridge Regression (SGD)    -47454.575066  46311.872168 -10354.579122  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>Distance_to_LA</th>\n",
       "      <th>Distance_to_SanDiego</th>\n",
       "      <th>Distance_to_SanFrancisco</th>\n",
       "      <th>Distance_to_SanJose</th>\n",
       "      <th>Distance_to_coast</th>\n",
       "      <th>Households</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Median_Income</th>\n",
       "      <th>Population</th>\n",
       "      <th>Tot_Bedrooms</th>\n",
       "      <th>Tot_Rooms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso Regression (Batch)</th>\n",
       "      <td>-20176.185162</td>\n",
       "      <td>-2084.835722</td>\n",
       "      <td>-6825.152954</td>\n",
       "      <td>-6492.168786</td>\n",
       "      <td>-27684.457405</td>\n",
       "      <td>14629.191393</td>\n",
       "      <td>-10861.516412</td>\n",
       "      <td>-18053.058686</td>\n",
       "      <td>13348.160105</td>\n",
       "      <td>70602.433193</td>\n",
       "      <td>-35306.545245</td>\n",
       "      <td>20973.774202</td>\n",
       "      <td>4858.812241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression (SGD)</th>\n",
       "      <td>-32034.923775</td>\n",
       "      <td>27689.312301</td>\n",
       "      <td>-20856.307251</td>\n",
       "      <td>21540.429826</td>\n",
       "      <td>-15324.856167</td>\n",
       "      <td>12800.377819</td>\n",
       "      <td>-61241.041903</td>\n",
       "      <td>-60343.644862</td>\n",
       "      <td>11063.575181</td>\n",
       "      <td>75246.628090</td>\n",
       "      <td>-40719.297069</td>\n",
       "      <td>47442.497916</td>\n",
       "      <td>-12068.668878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression (Batch)</th>\n",
       "      <td>-20176.185162</td>\n",
       "      <td>-2084.835722</td>\n",
       "      <td>-6825.152954</td>\n",
       "      <td>-6492.168786</td>\n",
       "      <td>-27684.457405</td>\n",
       "      <td>14629.191393</td>\n",
       "      <td>-10861.516412</td>\n",
       "      <td>-18053.058687</td>\n",
       "      <td>13348.160105</td>\n",
       "      <td>70602.433193</td>\n",
       "      <td>-35306.545246</td>\n",
       "      <td>20973.774202</td>\n",
       "      <td>4858.812241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression (SGD)</th>\n",
       "      <td>-28008.391224</td>\n",
       "      <td>1816.559226</td>\n",
       "      <td>-5671.379385</td>\n",
       "      <td>-1293.516133</td>\n",
       "      <td>-23470.632090</td>\n",
       "      <td>20885.065028</td>\n",
       "      <td>-16572.175371</td>\n",
       "      <td>-34247.249948</td>\n",
       "      <td>12961.537953</td>\n",
       "      <td>72603.361972</td>\n",
       "      <td>-45007.535020</td>\n",
       "      <td>33638.233951</td>\n",
       "      <td>-5338.291288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression (Batch)</th>\n",
       "      <td>-20176.180846</td>\n",
       "      <td>-2084.836299</td>\n",
       "      <td>-6825.152615</td>\n",
       "      <td>-6492.168945</td>\n",
       "      <td>-27684.457945</td>\n",
       "      <td>14629.187268</td>\n",
       "      <td>-10861.515065</td>\n",
       "      <td>-18053.054345</td>\n",
       "      <td>13348.159007</td>\n",
       "      <td>70602.428214</td>\n",
       "      <td>-35306.536058</td>\n",
       "      <td>20973.767744</td>\n",
       "      <td>4858.813852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression (SGD)</th>\n",
       "      <td>-30729.532934</td>\n",
       "      <td>24890.138073</td>\n",
       "      <td>-18295.015591</td>\n",
       "      <td>20815.974634</td>\n",
       "      <td>-13401.047652</td>\n",
       "      <td>13899.321323</td>\n",
       "      <td>-56603.380009</td>\n",
       "      <td>-57823.532751</td>\n",
       "      <td>11002.184735</td>\n",
       "      <td>75063.448330</td>\n",
       "      <td>-47454.575066</td>\n",
       "      <td>46311.872168</td>\n",
       "      <td>-10354.579122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T18:17:15.938730Z",
     "start_time": "2025-12-24T18:17:15.934962Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3d063fff8a757bc1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
